<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Native Speaker | 文本语音</title>
    <link rel="stylesheet" type="text/css" href="css/文本语音.css">
    <link rel="stylesheet" type="text/css" href="css/native导航栏.css">
    <link rel="stylesheet" type="text/css" href="css/pronunciation-panel.css">
  </head>
<body>
  <!-- 导航栏 -->
  <div class="nav">
        <ul>
            <li><a href="Native Speaker 首页.html" >首页</a></li>
            <li><a href="文本、语音.html" target="_self">口语交流制定</a></li>
            <li><a href="上传照片、视频.html" target="_self">物体英文识别</a></li>

            <li class="end">
                <a href="#">更多</a>
                <ul class="dropdown">
                    <li><a href="#">关于我们</a></li>
                    <li><a href="#">价格</a></li><br>
                    <li><a href="#">帮助</a></li>

                </ul>
            </li>
        </ul>
  </div>
    
  <div class="fontfirst"><h1>智能 | 口语交流制定</h1>
    <h2>根据语境描述、模糊搜查、语音提问，总能地道回答</h2>
    </div>

  <div class="body" id="app">
    <!-- 主体区域 -->

    <section id="todoapp">
    
    <!-- 输入框 -->
    <header class="header">
      <input v-model="inputValue" @keyup.enter="handleSubmit" autofocus="autofocus" autocomplete="off" placeholder="请输入咨询内容"
        class="new-todo" />                                 <!-- 收集文本 -->   
        <!-- <input type="file" id="zhaopian" accept="image/*">  收集照片 -->
    </header>

    <!-- 列表区域 -->
    <section class="main">
      <ul class="todo-list">
        <li class="todo" v-for="(item,index) in list">
          <div class="view">
            <span class="index">{{ index+1 }}.</span>
            <label>{{ item }}</label>
            <button class="destroy" @click="remove(index)"></button>
          </div>
        </li>
      </ul>
    </section>
    <!-- 统计和清空 -->
    <footer class="footer" v-show="list.length">
      <span class="todo-count" >
        <strong>{{ list.length }}</strong> words left
      </span>
      <button class="clear-completed" @click="clear">
        Clear
      </button>
    </footer>
    </section>
    <!-- 底部 -->
    <br>        <!-- 收集发音偏好 -->                                                    
    <input v-model="inputValueX"  autofocus="autofocus" autocomplete="off" placeholder="你想要的发音" class="in2"/>       <br>
    <!-- 收集语音 -->
        
        <button id="start" class="borderr">开始录制</button>
        <button id="stop" class="borderr" disabled>停止录制</button>
        <!-- 提交按钮（发送给后端） -->
        <button type="button"  class="borderr" @click="handleSubmit">Submit</button>
    
      <!-- <audio id="audio" controls ></audio>      暂不播放，后续需要可以打开 -->

     <!-- 同界面版本，收到后端返回之后：根据实际数据渲染 多条 数据 -->
    <section id="results">
      <div v-for="(text, index) in results_text" :key="index" class="chat-message">
        <!-- 显示文本 -->
        <div id="chatBox" class="chat-message">
          <p>{{ text }}</p>
        </div>
        <!-- 显示音频 -->
        <audio controls>
          <source :src="results_audio[index]" type="audio/mp3">
        </audio> <!-- 渲染音频 -->
      </div>
    </section>
</div>        

<!-- 发音评估上拉栏模块（修正class名，确保样式生效） -->
<div id="pronunciation-panel" class="pronunciation-panel" :class="{ expanded: isPanelExpanded, displayed: isPanelDisplayed }">
  <div class="pronunciation-toggle-button" @click="togglePanel">
    <span v-if="!isPanelExpanded" >发音评估 ▲</span>
    <span v-else>发音评估 ▼</span>
  </div>
  <div class="pronunciation-info-content" style="display:flex;flex-direction:column;height:65vh;padding-bottom:0;">
    <!-- 历史内容区，最新在下方，可滚动，内容从上往下堆积 -->
    <div class="pronunciation-history-content" style="flex:1;overflow-y:auto;display:flex;flex-direction:column;justify-content:flex-start;">
      <div v-for="(item, idx) in aiHistory" :key="idx" style="margin-bottom:18px;">
        <div style="font-weight:bold;color:#4a9eff;">{{ item.question }}</div>
        <audio v-if="item.audio" :src="item.audio" controls style="margin:4px 0;"></audio>
        <div v-html="renderMarkdown(item.answer)" style="background:#f5f5f5;border-radius:10px;padding:8px 12px;margin-top:4px;font-size:16px;font-weight:bold;"></div>
      </div>
      <!-- 当前评估结果 -->
      <div v-if="aiResponse || isLoading" style="margin-bottom:18px;">
        <div v-if="inputValue" style="font-weight:bold;color:#4a9eff;">{{ inputValue }}</div>
        <audio v-if="audioUrl" :src="audioUrl" controls style="margin:4px 0;"></audio>
        <div v-if="aiResponse" v-html="renderMarkdown(aiResponse)" style="background:#f5f5f5;border-radius:10px;padding:8px 12px;margin-top:4px;font-size:16px;font-weight:bold;"></div>
        <div v-else-if="isLoading" class="loading-animation">
          <div class="loading-dot"></div>
          <div class="loading-dot"></div>
          <div class="loading-dot"></div>
        </div>
      </div>
    </div>
    <!-- 输入区固定在底部 -->
    <div style="display:flex;align-items:center;gap:10px;padding:10px 0 0 0;margin-top:auto;">
      <input v-model="inputValue" @keyup.enter="handleSubmit" placeholder="请输入要评估的句子或直接录音" class="pronunciation-message-input" style="flex:1;"/>
      <button @click="startRecord" :disabled="isRecording" class="borderr">开始录制</button>
      <button @click="stopRecord" :disabled="!isRecording" class="borderr">结束录制</button>
      <button @click="handleSubmit" class="pronunciation-send-button">提交评估</button>
    </div>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script>
  var app = new Vue({
    el: "#app",
    data: {
      list: [],
      inputValue: "",
      inputValueX: "",
      prompt: ""
    },
    methods: {
      renderMarkdown(text) {
        return marked.parse(text || '');
      },
      handleSubmit() {
        this.add();
        submitForm();
      },
      add: function () {
        this.list.push(this.inputValue);
        this.inputValue = " ";
      },
      remove: function (index) {
        this.list.splice(index, 1);
      },
      clear: function () {
        this.list = [];
      }
    }
  });

  var resultsApp = new Vue({
    el: '#results',
    data: {
      results_text: [],
      results_audio: []
    },
    methods: {
      updateResults(response) {
        this.results_text.push(response.data.text);
        this.results_audio.push(response.data.audio);
      }
    }
  });

  //录音收集
  const startButton = document.getElementById('start');
  const stopButton = document.getElementById('stop');
  const audioElement = document.getElementById('audio');
  let audioFile;

  navigator.mediaDevices.getUserMedia({ audio: true })
    .then(stream => {
      let mediaRecorder = createMediaRecorder(stream);

      function createMediaRecorder(stream) {
        const mediaRecorder = new MediaRecorder(stream);
        let chunks = [];

        mediaRecorder.ondataavailable = function (e) {
          chunks.push(e.data);
        };

        mediaRecorder.onstop = function () {
          const blob = new Blob(chunks, { 'type': 'audio/mp3; codecs=opus' });
          chunks = [];
          const audioURL = URL.createObjectURL(blob);
          audioFile = new File([blob], "recording.mp3", { type: "audio/mp3" });
        };

        return mediaRecorder;
      }

      startButton.addEventListener('click', () => {
        startButton.disabled = true;
        stopButton.disabled = false;
        mediaRecorder.start();
      });

      stopButton.addEventListener('click', () => {
        startButton.disabled = false;
        stopButton.disabled = true;
        mediaRecorder.stop();
      });
    })
    .catch(error => {
      console.error('获取用户媒体设备失败:', error);
    });

  function submitForm() {
    const inputValue = app.inputValue;
    const formData = new FormData();

    if (inputValue) {
      formData.append('text', inputValue);
    } else {
      formData.append('text', ' ');
    }

    if (audioFile) {
      formData.append('file', audioFile);
    } else {
      formData.append('file', new Blob(), 'empty-audio.mp3');
    }

    formData.append('image', new Blob(), 'empty-image.png');

    axios.post('https://natispeaker.chainpray.top/submit', formData, {
      headers: {
        'Content-Type': 'multipart/form-data'
      }
    })
      .then(response => {
        console.log('Success:', response.data);
        resultsApp.updateResults(response);
      })
      .catch(error => {
        console.error('Error:', error);
      });
    if (inputValue != ' ') {
      app.add();
    }
  }

  // AI接口调用
  var pronunciationApp = new Vue({
    el: '#pronunciation-panel',
    data: {
      isPanelExpanded: false,
      isPanelDisplayed: true,
      inputValue: '',
      aiResponse: '',
      isLoading: false,
      isRecording: false,
      audioFile: null,
      audioUrl: '',
      mediaRecorder: null,
      chunks: [],
      aiHistory: [], // 新增历史消息数组
      recognizedText: '' // 新增：保存语音识别内容
    },
    methods: {
      renderMarkdown(text) {
        return marked.parse(text || '');
      },
      togglePanel() {
        this.isPanelExpanded = !this.isPanelExpanded;
        this.$nextTick(() => {
          // 展开时滚动到底部
          const content = this.$el.querySelector('.pronunciation-history-content');
          if(content) content.scrollTop = content.scrollHeight;
        });
      },
      closePanel() {
        this.isPanelDisplayed = false;
      },
      async handleSubmit() {
        // 优先用 recognizedText
        const textToSend = this.recognizedText || this.inputValue;
        if (!textToSend && !this.audioFile) return;
        this.aiResponse = '';
        this.isLoading = true;
        let prompt = '请帮我评估一下下面我说的句子的发音（英式和美式和其他等发音）并给出建议：' + (textToSend || '');
        const apiKey = 'sk-1293377df9b2444d9bf8fec5625af9fe';
        const apiUrl = 'https://api.deepseek.com/v1/chat/completions';
        try {
          const response = await fetch(apiUrl, {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${apiKey}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: "deepseek-chat",
              messages: [{ role: "user", content: prompt }],
              stream: true,
            }),
          });
          if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
          }
          const reader = response.body.getReader();
          const decoder = new TextDecoder();
          const readChunk = async () => {
            const { done, value } = await reader.read();
            if (done) {
              this.isLoading = false;
              // 评估完成后将本次内容加入历史
              this.aiHistory.push({
                question: textToSend,
                audio: this.audioUrl,
                answer: this.aiResponse
              });
              this.inputValue = '';
              this.audioFile = null;
              this.audioUrl = '';
              this.recognizedText = '';
              this.$nextTick(() => {
                const content = this.$el.querySelector('.pronunciation-history-content');
                if(content) content.scrollTop = content.scrollHeight;
              });
              return;
            }
            const chunk = decoder.decode(value);
            const lines = chunk.split('\n').filter(line => line.trim());
            lines.forEach(line => {
              if (line.startsWith('data:')) {
                try {
                  const data = JSON.parse(line.replace('data:', ''));
                  if (data.choices?.[0]?.delta?.content) {
                    this.aiResponse += data.choices[0].delta.content;
                  }
                } catch (e) {
                  console.error("Failed to parse chunk:", e);
                }
              }
            });
            readChunk();
          };
          readChunk();
        } catch (error) {
          this.isLoading = false;
          this.aiResponse = '请求失败';
        }
      },
      startRecord() {
        this.isRecording = true;
        this.chunks = [];
        this.recognizedText = '';
        // 语音识别
        if (window.SpeechRecognition || window.webkitSpeechRecognition) {
          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          const recognition = new SpeechRecognition();
          recognition.lang = 'zh-CN';
          recognition.continuous = false;
          recognition.interimResults = false;
          recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            this.recognizedText = transcript; // 只保存到 recognizedText，不赋值 inputValue
          };
          recognition.onerror = (event) => {
            console.error('语音识别错误:', event.error);
          };
          recognition.start();
          this._recognition = recognition;
        }
        navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
          this.mediaRecorder = new MediaRecorder(stream);
          this.mediaRecorder.ondataavailable = (e) => {
            this.chunks.push(e.data);
          };
          this.mediaRecorder.onstop = () => {
            const blob = new Blob(this.chunks, { type: 'audio/mp3' });
            this.audioFile = new File([blob], 'recording.mp3', { type: 'audio/mp3' });
            this.audioUrl = URL.createObjectURL(blob);
            this.isRecording = false;
          };
          this.mediaRecorder.start();
        })
      },
      stopRecord() {
        if (this.mediaRecorder && this.isRecording) {
          this.mediaRecorder.stop();
        }
      }
    }
  });
</script>
</body>
</html>